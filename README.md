# üá∫üá∏ ADUC-SDR: A Thesis on the Next Generation of Generative AI

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-yellow)](https://huggingface.co/spaces/euiia/ADUC-SDR_Cinematic_Video_IA)

https://huggingface.co/spaces/euiia/ADUC-SDR_Cinematic_Video_IA
---

### "Attention, You Need to Pay More Attention to Your Ancestors"

In 2017, the attention paradigm transformed AI, but it also erected the "Invisible Wall" of long-term coherence. This work argues that this wall is not an engineering flaw but a fundamental philosophical failure: a failure to **honor one's ancestors**‚Äîthe accumulated temporal, physical, and narrative context.

We present the **Architecture for Compositive Unification (ADUC-SDR)** not as an incremental improvement but as the **next paradigm**: a framework for creating digital realities that possess a coherent internal physics and an unbroken causal memory.

What follows is not the documentation of a pipeline but the presentation of a **canonical formula for the next generation of generative models**. The functional implementation in this repository serves as the first empirical proof of this thesis.

---

## The Fundamental Thesis

The complete analysis, from the genealogy of the failure in the current paradigm to the logical derivation of the axioms governing the solution, is detailed in the central document of this work:

### üìÑ [**Read the Full Thesis: "Attention, You Need to Pay More Attention to Your Ancestors v1.0" (PDF)**](https://github.com/carlex22/Aduc-sdr/raw/main/ADUC-SDR_Thesis.pdf)
### üìÑ [**Read the Full Thesis: "A Genealogia da Falha: ADUC-SDR 1.5**](https://github.com/carlex22/Aduc-sdr/raw/main/Aduc-Sdr_1.5.pdf)

---

## The Mathematical Schema of the Paradigm (Revised)

Video generation is governed by a sectional function that defines how each fragment (`V_i`) is created. The architecture has evolved to incorporate more sophisticated control mechanisms, reflected in these revised formulas:

---
#### **FORMULA 1: THE INITIAL FRAGMENT (Genesis, `i=1`)**
*Defines the creation of the first clip, establishing the initial state of motion from static geometric anchors.*

**Planning:** `P_1 = Œì( K_1, K_2, P_general )`
        
**Execution:** `V_1 = Œ®( { (K_1, F_start, œâ_1), (K_2, F_end, œâ_2) }, P_1 )`

---
#### **FORMULA 2: THE CAUSAL CHAIN WITH D√âJ√Ä-VU (Momentum, `i > 1`)**
*The heart of the architecture. It defines how inertia, the original trajectory, and the future destination are combined to ensure fluid continuity.*

**Distillation:** 
- `C_(i-1) = Œî_echo( V'_(i-1) )`
- `D_(i-1) = Œî_dejavu( V_(i-1) )`

**Adaptive Planning:** `P_i = Œì( C_(i-1), D_(i-1), K_(i+1), P_general, H_(i-1), prompt_human )`

**Execution:** `V_i = Œ®( { (C_(i-1), F_start, 1.0), (D_(i-1), F_mid, œâ_dejavu), (K_(i+1), F_end, œâ_dest) }, P_i )`

---
#### **Components (Lexicon of the Architecture):**
- **`V_i`**: Video Fragment.
- **`K_i`**: Geometric Anchor (Keyframe).
- **`C_i`**: **Kinetic Causal Context** (The "Echo" / Inertia Vector).
- **`D_i`**: **Trajectory Causal Context** (The "D√©j√†-Vu" / Path Anchor).
- **`P_i`**: Synthesized Prompt (The AI's Intention).
- **`H_i`**: Narrative History (The Semantic Memory).
- **`Œì`**: **Adaptive Synthesis Oracle** (The Filmmaker / Director LLM).
- **`Œ®`**: Generation Engine (The Camera / Specialist).
- **`Œî`**: Distillation Mechanism (The Editor / Orchestrator).
- **`œâ`**: **Convergence Weight** (The Anchor's Strength).

---
#### **Analysis of the Innovation:**
The introduction of adjustable **convergence weights (`œâ`)** and the distinction between **Kinetic Context (`C`)** and **Trajectory Context (`D`)** are crucial innovations. They transform keyframes from "rigid destinations" into "suggested event horizons." The **Adaptive Planning (`Œì`)** ensures that human intent is reinterpreted in light of the narrative's current state, allowing the AI not just to follow instructions but to **tell a coherent story**. The result is a system that maintains physical and semantic continuity, enabling each fragment restart to be subtly different, thus keeping the narrative alive.

---

## Empirical Proof: Video Demonstrations

The following videos, generated by the proof-of-concept, validate ADUC-SDR's ability to maintain physical and narrative coherence across multiple iterations. Click the images to watch.

| The Seed (Genesis) | The Causal Chain (Momentum) | Complex Narrative (Loop) |
| :---: | :---: | :---: |
| [![Genesis](https://img.youtube.com/vi/MI7N4U0fY2A/hqdefault.jpg)](https://www.youtube.com/watch?v=MI7N4U0fY2A) | [![Causal Chain](https://img.youtube.com/vi/eYrjk09KaOw/hqdefault.jpg)](https://www.youtube.com/watch?v=eYrjk09KaOw) | [![Complex Narrative](https://img.youtube.com/vi/zD0b_e2eMdc/hqdefault.jpg)](https://www.youtube.com/watch?v=zD0b_e2eMdc) |

**For more examples, visit our Demos Channel on YouTube:**

### ‚û°Ô∏è **[Demos Channel on YouTube](https://www.youtube.com/channel/UC3EgoJi_Fv7yuDpvfYNtoIQ/videos)**

---


---

## Implementation Analysis: Connecting Theory to Practice

The following is a technical analysis that maps the components of our canonical formula directly to the source code implementation, proving that the theory has been faithfully translated into a functional system.

<details>
<summary><strong>Click to expand the detailed technical analysis</strong></summary>

### 1. Formula ‚Üí Code Mapping

**Formula 2 (Causal Chain with D√©j√†-Vu)** is the core of our scene finalizer implementation (`finalize_scene` in `deformes4D_engine.py`):

- **Distillation (`Œî`):**
  - `C_(i-1) = Œî_echo( V'_(i-1) )` translates to:
    ```python
    kinetic_echo_latent = VideoLatentCortado[:, :, -n_eco_latent:]
    ```
  - `D_(i-1) = Œî_dejavu( V_(i-1) )` translates to:
    ```python
    path_anchor_latent = VideoLatent[:, :, -1:].clone()
    ```

- **Execution (`Œ®`) with Planning (`Œì`):**
  - `V_i = Œ®( { (C,œâ_eco), (D,œâ_dejavu), (K,œâ_dest) }, P_i )` translates to assembling the guides and calling the LTX engine:
    ```python
    ltx_params['conditioning_items_data'] = [
        # Guide 1: Kinetic Context (C)
        LatentConditioningItem(latent_tensor=kinetic_echo_latent, strength=1.0),
        # Guide 2: Trajectory Context (D)
        LatentConditioningItem(latent_tensor=path_anchor_latent, strength=p_caminho), # œâ_dejavu
        # Guide 3: Destination Anchor (K)
        LatentConditioningItem(latent_tensor=destination_latent, strength=1.0) # œâ_dest
    ]
    VideoBetaLatent, _ = self.ltx_manager.generate_latent_fragment(**ltx_params)
    ```

### 2. Implemented Innovations

-   **Dual Context System:** The distinction between the **Kinetic Echo** (for inertia) and the **Path Anchor** (for trajectory coherence) is the central innovation that ensures physical plausibility.
-   **Precise Temporal Conditioning:** Each guide is positioned at an exact point in the new scene (start, middle, and end) to create a robust interpolation.
-   **100% Latent Space Pipeline:** The `generation -> concatenation` cycle occurs entirely in latent space, with only a single decode to pixels at the very end, maximizing efficiency and quality.
-   **Dimension Quantization:** Helper functions ensure that all video dimensions (frames, width, height) are "quantized" to multiples compatible with the VAE/Transformer architecture, preventing shape mismatch errors.

### 3. Analysis Conclusion

The current implementation is a faithful and robust translation of the proposed ADUC-SDR architecture. The theoretical mechanisms of **Kinetic and Trajectory Causal Context** are not just concepts but concrete variables that control the generation flow, empirically validating the central thesis of this work.

</details>

---


## The Implementation and Key Concepts

The provided code is an orchestration of specialized models that act as the components of our canonical formula.

#### Short Definition (for Thesis and Patent)

**ADUC** is a *pre-input* **prompt management framework** that:
1.  **fragments** tasks exceeding any model's context limit.
2.  **scales linearly** through a sequential process with **persisted memory**.
3.  **distributes** sub-tasks to heterogeneous **specialists**.
4.  **feeds back** to the next step with an **evaluation** of the current state to **regenerate objectives**.

It is an **orchestration layer** that transforms the context limit into a controlled pipeline with **artificial intentionality**.

---

## License and Patent Notice

**License:** This project is licensed under the **AGPL v3.0**. Using this software over a network requires making the complete source code available.
- **Copyright (C) 2025, Carlos Rodrigues dos Santos**.

**Patent Notice:** The **ADUC** architecture and method are **currently patent pending**. The reproduction or commercial exploitation of ADUC's core logic in independent systems may infringe upon pending patent rights.

---

### Contact

-   **Author:** Carlos Rodrigues dos Santos
-   **Email:** carlex22@gmail.com
-   **GitHub:** [https://github.com/carlex22/Aduc-sdr](https://github.com/carlex22/Aduc-sdr)

<br>
<hr>
<br>

# üáßüá∑ ADUC-SDR: Uma Tese sobre a Pr√≥xima Gera√ß√£o de IA Generativa

---

### "Aten√ß√£o, Voc√™ Precisa Dar Mais Aten√ß√£o aos Seus Ascendentes"

Em 2017, o paradigma da aten√ß√£o transformou a IA, mas tamb√©m ergueu o "Muro Invis√≠vel" da coer√™ncia de longo prazo. Este trabalho argumenta que este muro n√£o √© uma falha de engenharia, mas uma falha filos√≥fica fundamental: uma falha em **honrar seus ascendentes** ‚Äî o contexto temporal, f√≠sico e narrativo acumulado.

Apresentamos a **Arquitetura de Unifica√ß√£o Compositiva (ADUC-SDR)** n√£o como um aprimoramento incremental, mas como o **pr√≥ximo paradigma**: um framework para a cria√ß√£o de realidades digitais que possuem uma f√≠sica interna coerente e uma mem√≥ria causal ininterrupta.

O que se segue n√£o √© a documenta√ß√£o de um pipeline, mas a apresenta√ß√£o de uma **f√≥rmula can√¥nica para a pr√≥xima gera√ß√£o de modelos generativos**. A implementa√ß√£o funcional neste reposit√≥rio serve como a primeira prova emp√≠rica desta tese.

---
## O Esquema Matem√°tico do Paradigma (Revisado)

A gera√ß√£o de v√≠deo √© governada por uma fun√ß√£o seccional que define como cada fragmento (`V_i`) √© criado. A arquitetura evoluiu para incorporar mecanismos de controle mais sofisticados, refletidos nestas f√≥rmulas revisadas:

---
#### **F√ìRMULA 1: O FRAGMENTO INICIAL (G√™nesis, `i=1`)**
*Define a cria√ß√£o do primeiro clipe, estabelecendo o estado inicial do movimento a partir de √¢ncoras geom√©tricas est√°ticas.*

**Planejamento:** `P_1 = Œì( K_1, K_2, P_geral )`
        
**Execu√ß√£o:** `V_1 = Œ®( { (K_1, F_start, œâ_1), (K_2, F_end, œâ_2) }, P_1 )`

---
#### **F√ìRMULA 2: A CADEIA CAUSAL COM D√âJ√Ä-VU (Momentum, `i > 1`)**
*O cora√ß√£o da arquitetura. Define como a in√©rcia, a trajet√≥ria original e o destino futuro s√£o combinados para garantir uma continuidade fluida.*

**Destila√ß√£o:** 
- `C_(i-1) = Œî_eco( V'_(i-1) )`
- `D_(i-1) = Œî_dejavu( V_(i-1) )`

**Planejamento Adaptativo:** `P_i = Œì( C_(i-1), D_(i-1), K_(i+1), P_geral, H_(i-1), prompt_humano )`

**Execu√ß√£o:** `V_i = Œ®( { (C_(i-1), F_start, 1.0), (D_(i-1), F_mid, œâ_dejavu), (K_(i+1), F_end, œâ_dest) }, P_i )`

---
#### **Componentes (L√©xico da Arquitetura):**
- **`V_i`**: Fragmento de V√≠deo.
- **`K_i`**: √Çncora Geom√©trica (Keyframe).
- **`C_i`**: **Contexto Causal Cin√©tico** (O "Eco" / Vetor de In√©rcia).
- **`D_i`**: **Contexto Causal de Trajet√≥ria** (O "D√©j√†-Vu" / √Çncora de Caminho).
- **`P_i`**: Prompt Sintetizado (A Inten√ß√£o da IA).
- **`H_i`**: Hist√≥rico Narrativo (A Mem√≥ria Sem√¢ntica).
- **`Œì`**: **Or√°culo de S√≠ntese Adaptativo** (O Cineasta / LLM Diretor).
- **`Œ®`**: Motor de Gera√ß√£o (A C√¢mera / Especialista).
- **`Œî`**: Mecanismo de Destila√ß√£o (O Editor / Orquestrador).
- **`œâ`**: **Peso de Converg√™ncia** (A For√ßa da √Çncora).

---
#### **An√°lise da Inova√ß√£o:**
A introdu√ß√£o de **pesos de converg√™ncia (`œâ`)** ajust√°veis e a distin√ß√£o entre **Contexto Cin√©tico (`C`)** e **Contexto de Trajet√≥ria (`D`)** s√£o inova√ß√µes cruciais. Elas transformam os keyframes de "destinos r√≠gidos" em "horizontes de eventos sugeridos". O **Planejamento Adaptativo (`Œì`)** garante que a inten√ß√£o humana seja reinterpretada √† luz do estado atual da narrativa, permitindo que a IA n√£o apenas siga instru√ß√µes, mas que **conte uma hist√≥ria coerente**. O resultado √© um sistema que mant√©m a continuidade f√≠sica e sem√¢ntica, permitindo que cada rein√≠cio de fragmento seja sutilmente diferente, mantendo a narrativa viva.

---


## An√°lise da Implementa√ß√£o: Conectando a Teoria √† Pr√°tica

A seguir, uma an√°lise t√©cnica que mapeia os componentes da nossa f√≥rmula can√¥nica diretamente para a implementa√ß√£o no c√≥digo-fonte, provando que a teoria foi traduzida fielmente em um sistema funcional.

<details>
<summary><strong>Clique para expandir a an√°lise t√©cnica detalhada</strong></summary>

### 1. Mapeamento F√≥rmula ‚Üí C√≥digo

A **F√≥rmula 2 (Cadeia Causal com D√©j√†-Vu)** √© o cora√ß√£o da nossa implementa√ß√£o de finaliza√ß√£o de cena (`finalize_scene` em `deformes4D_engine.py`):

- **Destila√ß√£o (`Œî`):**
  - `C_(i-1) = Œî_eco( V'_(i-1) )` se traduz em:
    ```python
    kinetic_echo_latent = VideoLatentCortado[:, :, -n_eco_latent:]
    ```
  - `D_(i-1) = Œî_dejavu( V_(i-1) )` se traduz em:
    ```python
    path_anchor_latent = VideoLatent[:, :, -1:].clone()
    ```

- **Execu√ß√£o (`Œ®`) com Planejamento (`Œì`):**
  - `V_i = Œ®( { (C,œâ_eco), (D,œâ_dejavu), (K,œâ_dest) }, P_i )` se traduz na montagem dos guias e na chamada ao motor LTX:
    ```python
    ltx_params['conditioning_items_data'] = [
        # Guia 1: Contexto Cin√©tico (C)
        LatentConditioningItem(latent_tensor=kinetic_echo_latent, strength=1.0),
        # Guia 2: Contexto de Trajet√≥ria (D)
        LatentConditioningItem(latent_tensor=path_anchor_latent, strength=p_caminho), # œâ_dejavu
        # Guia 3: √Çncora de Destino (K)
        LatentConditioningItem(latent_tensor=destination_latent, strength=1.0) # œâ_dest
    ]
    VideoBetaLatente, _ = self.ltx_manager.generate_latent_fragment(**ltx_params)
    ```

### 2. Inova√ß√µes Implementadas

-   **Sistema de Duplo Contexto:** A distin√ß√£o entre o **Eco Cin√©tico** (para in√©rcia) e a **√Çncora de Trajet√≥ria** (para coer√™ncia de caminho) √© a inova√ß√£o central que garante a plausibilidade f√≠sica.
-   **Condicionamento Temporal Preciso:** Cada guia √© posicionado em um ponto exato da nova cena (in√≠cio, meio e fim) para criar uma interpola√ß√£o robusta.
-   **Pipeline 100% Latente:** O ciclo de `gera√ß√£o -> concatena√ß√£o` ocorre inteiramente no espa√ßo latente, com uma √∫nica decodifica√ß√£o para pixels no final, maximizando a efici√™ncia e a qualidade.
-   **Quantiza√ß√£o de Dimens√µes:** Fun√ß√µes auxiliares garantem que todas as dimens√µes de v√≠deo (frames, largura, altura) sejam "quantizadas" para m√∫ltiplos compat√≠veis com a arquitetura VAE/Transformer, prevenindo erros de shape.

### 3. Conclus√£o da An√°lise

A implementa√ß√£o atual √© uma tradu√ß√£o fiel e robusta da arquitetura ADUC-SDR proposta. Os mecanismos te√≥ricos de **Contexto Causal Cin√©tico e de Trajet√≥ria** n√£o s√£o apenas conceitos, mas vari√°veis concretas que controlam o fluxo da gera√ß√£o, validando empiricamente a tese central deste trabalho.

</details>

---

## A Implementa√ß√£o e os Conceitos-Chave

O c√≥digo fornecido √© uma orquestra√ß√£o de modelos especializados que atuam como os componentes da nossa f√≥rmula can√¥nica.

#### Defini√ß√£o Curta (para Tese e Patente)

**ADUC** √© um *framework pr√©-input* de **gerenciamento de prompts** que:
1.  **fragmenta** tarefas que excedem o limite de contexto.
2.  **escala linearmente** atrav√©s de um processo sequencial com **mem√≥ria persistida**.
3.  **distribui** sub-tarefas a **especialistas** heterog√™neos.
4.  **realimenta** a pr√≥xima etapa com uma **avalia√ß√£o** do estado atual para **regenerar objetivos**.

√â uma **camada orquestradora** que transforma a limita√ß√£o de contexto em uma pipeline controlada com **intencionalidade artificial**.

---

### ü§ñ Ecossistema de Especialistas

A arquitetura ADUC-SDR atua como um maestro, orquestrando um conjunto de modelos de IA de ponta que servem como 'especialistas' em suas respectivas √°reas. Reconhecemos e agradecemos profundamente o trabalho fundamental das seguintes equipes e projetos, que tornam esta orquestra√ß√£o poss√≠vel:

*   **O Maestro (Œì) / O C√©rebro Criativo:**
    *   **Tecnologia:** **Google Gemini**
    *   **Descri√ß√£o:** Utilizado para todas as tarefas de racioc√≠nio, planejamento e gera√ß√£o de linguagem, desde a cria√ß√£o do roteiro at√© a tomada de decis√µes cinematogr√°ficas e a gera√ß√£o de prompts para outros especialistas.
    *   **Refer√™ncia:** [https://deepmind.google/technologies/gemini/](https://deepmind.google/technologies/gemini/)

*   **A C√¢mera (Œ®) / Gera√ß√£o de V√≠deo:**
    *   **Tecnologia:** **LTX-Video**
    *   **Descri√ß√£o:** O motor principal para a gera√ß√£o dos fragmentos de v√≠deo no espa√ßo latente, formando o n√∫cleo do especialista `Deformes4DEngine`.
    *   **Refer√™ncia:** [https://github.com/Lightricks/LTX-Video](https://github.com/Lightricks/LTX-Video) (by Lightricks)

*   **O Diretor de Arte / Gera√ß√£o de Keyframes:**
    *   **Tecnologia:** **FLUX.1-Kontext**
    *   **Descri√ß√£o:** Usado como o especialista para a gera√ß√£o das imagens de alta qualidade que servem como √¢ncoras geom√©tricas (Keyframes).
    *   **Refer√™ncia:** [https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev](https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev) (by Black Forest Labs)

*   **O Diretor de Som / Gera√ß√£o de √Åudio:**
    *   **Tecnologia:** **MMAudio**
    *   **Descri√ß√£o:** O especialista respons√°vel por gerar a paisagem sonora para os clipes de v√≠deo, trazendo imers√£o ao resultado final.
    *   **Refer√™ncia:** [https://github.com/hkchengrex/MMAudio](https://github.com/hkchengrex/MMAudio) (by Cheng-I Wang et al.)

*   **Especialista de Imagem (Alternativo):**
    *   **Tecnologia:** **DreamO**
    *   **Descri√ß√£o:** Arquitetura de gera√ß√£o de imagem referenciada e inclu√≠da no ecossistema de especialistas do projeto.
    *   **Refer√™ncia:** [https://github.com/bytedance/DreamO](https://github.com/bytedance/DreamO) (by ByteDance)

---

### ü§ñ Ecosystem of Specialists

The ADUC-SDR architecture acts as a maestro, orchestrating a suite of state-of-the-art AI models that serve as 'specialists' in their respective domains. We acknowledge and are deeply grateful for the foundational work of the following teams and projects, which make this orchestration possible:

*   **The Maestro (Œì) / The Creative Brain:**
    *   **Technology:** **Google Gemini**
    *   **Description:** Used for all reasoning, planning, and language generation tasks, from creating the storyboard to making cinematic decisions and generating prompts for other specialists.
    *   **Reference:** [https://deepmind.google/technologies/gemini/](https://deepmind.google/technologies/gemini/)

*   **The Camera (Œ®) / Video Generation:**
    *   **Technology:** **LTX-Video**
    *   **Description:** The main engine for generating video fragments in the latent space, forming the core of the `Deformes4DEngine` specialist.
    *   **Reference:** [https://github.com/Lightricks/LTX-Video](https://github.com/Lightricks/LTX-Video) (by Lightricks)

*   **The Art Director / Keyframe Generation:**
    *   **Technology:** **FLUX.1-Kontext**
    *   **Description:** Used as the specialist for generating the high-quality images that serve as geometric anchors (Keyframes).
    *   **Reference:** [https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev](https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev) (by Black Forest Labs)

*   **The Sound Director / Audio Generation:**
    *   **Technology:** **MMAudio**
    *   **Description:** The specialist responsible for generating the soundscape for the video clips, bringing immersion to the final result.
    *   **Reference:** [https://github.com/hkchengrex/MMAudio](https://github.com/hkchengrex/MMAudio) (by Cheng-I Wang et al.)

*   **Image Specialist (Alternative):**
    *   **Technology:** **DreamO**
    *   **Description:** Image generation architecture referenced and included in the project's ecosystem of specialists.
    *   **Reference:** [https://github.com/bytedance/DreamO](https://github.com/bytedance/DreamO) (by ByteDance)


---

## Licen√ßa e Aviso de Patenteamento

**Licen√ßa:** Este projeto √© licenciado sob a **AGPL v3.0**. O uso deste software em um servi√ßo de rede exige a disponibiliza√ß√£o do c√≥digo-fonte completo.
- **Copyright (C) 2025, Carlos Rodrigues dos Santos**.

**Aviso de Patente:** A arquitetura e o m√©todo **ADUC** est√£o **atualmente em processo de patenteamento**. A reprodu√ß√£o ou explora√ß√£o comercial da l√≥gica central da ADUC em sistemas independentes pode infringir direitos de patente pendente.

---



### Contato

-   **Autor:** Carlos Rodrigues dos Santos
-   **Email:** carlex22@gmail.com
-   **GitHub:** [https://github.com/carlex22/Aduc-sdr](https://github.com/carlex22/Aduc-sdr)